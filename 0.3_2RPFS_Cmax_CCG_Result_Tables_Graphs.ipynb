{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2RPFS Problem (Cmax objective) - Tables and Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running this, notebook, please run notebooks 0.1 and 0.2 (in this order)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, fnmatch\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "import glob\n",
    "import seaborn as sns\n",
    "import gzip\n",
    "import matplotlib.style as style\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if sys.version_info[0] < 3: \n",
    "    from StringIO import StringIO\n",
    "else:\n",
    "    from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linestyle_tuple = [\n",
    "     ('dotted',                (0, (1, 1))),\n",
    "     ('dashed',                (0, (5, 5))),\n",
    "     ('densely dashed',        (0, (5, 1))),\n",
    "     ('dashdotdotted',         (0, (3, 5, 1, 5, 1, 5))),\n",
    "     ('densely dashdotdotted', (0, (3, 1, 1, 1, 1, 1))),\n",
    "\n",
    "     ('dashdotted',            (0, (3, 5, 1, 5))),\n",
    "     ('densely dashdotted',    (0, (3, 1, 1, 1))),\n",
    "     \n",
    "     ('loosely dashed',        (0, (5, 10))),\n",
    "     ('loosely dashdotted',    (0, (3, 10, 1, 10))),\n",
    "     \n",
    "\n",
    "     ('loosely dashdotdotted', (0, (3, 10, 1, 10, 1, 10))),\n",
    "     ('densely dotted',        (0, (1, 1))),\n",
    "     ('loosely dotted',        (0, (1, 10)))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List files in the result folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultfolder = os.path.join(os.getcwd(), 'results', 'consolidated')\n",
    "rpfs_file = os.path.join(resultfolder, '2RPFS_Cmax_all_results.csv')\n",
    "det_file = os.path.join(resultfolder, 'PFSP_Cmax_deterministic_all_results.csv')\n",
    "stoc_file = os.path.join(resultfolder, 'simgrasp_cmax_ying_stochgrasp_results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the output folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputfolder = os.path.join(os.getcwd(), 'results', 'consolidated')\n",
    "outputfolder_graph = os.path.join(os.getcwd(), 'results', 'consolidated', 'graphs')\n",
    "if not os.path.exists(outputfolder_graph):\n",
    "    os.makedirs(outputfolder_graph)\n",
    "#print('Saving files on folder: ' + outputfolder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process consolidated CSV result files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rpfs = pd.read_csv(rpfs_file, delimiter=';')\n",
    "df_dpfs = pd.read_csv(det_file, delimiter=';')\n",
    "df_rpfs.drop(columns=['executionId'], inplace=True)\n",
    "df_dpfs.drop(columns=['executionId'], inplace=True)\n",
    "df_stoc = pd.read_csv(stoc_file, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Robust dataframe: calculating new fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rpfs['optimal'] = df_rpfs['is_optimal'] & df_rpfs['validated'] & (df_rpfs['gap'] <= 1e-5)\n",
    "df_rpfs['time_limit'] = 7200.0\n",
    "df_rpfs['time'] = np.minimum(df_rpfs['time_spent'], df_rpfs['time_limit'])\n",
    "df_rpfs['gap'] = df_rpfs['gap'] * 100\n",
    "df_rpfs['worstcase_cost'] = df_rpfs['cmax_dp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rpfs_wagner = df_rpfs[(df_rpfs['model'] == 'Wagner')]\n",
    "df_rpfs_wilson = df_rpfs[(df_rpfs['model'] == 'Wilson')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rpfs[['time', 'time_spent']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rpfs.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing the stochastic solutions dataframe (SimGRASP) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stoc.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_budget_gamma_column(df):\n",
    "    # new data frame with split value columns \n",
    "    new = df[\"budget_Gamma\"].str.split(\" \", n = 1, expand = True) \n",
    "    # making separate first name column from new data frame \n",
    "    df[\"Gamma1\"]= new[0] \n",
    "    # making separate last name column from new data frame \n",
    "    df[\"Gamma2\"]= new[1] \n",
    "    # convert Gamma columns to numeric\n",
    "    df[\"Gamma1\"] = pd.to_numeric(df[\"Gamma1\"], errors='coerce')\n",
    "    df[\"Gamma2\"] = pd.to_numeric(df[\"Gamma2\"], errors='coerce')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stoc['instance_name'] = df_stoc['rob_pfsp_instance']\n",
    "\n",
    "budget_list = []\n",
    "for g1 in [20, 40, 60, 80, 100]:\n",
    "    for g2 in [20, 40, 60, 80, 100]:\n",
    "        budget_list.append('{} {}'.format(g1, g2))\n",
    "df_ssgrasp = pd.melt(df_stoc, id_vars=['n', 'm', 'alpha', 'instance_name', 'stochsol_exp_cost', 'stochsol_time'], \n",
    "                     value_vars=budget_list, var_name='budget_Gamma', value_name='worstcase_cost')\n",
    "df_ssgrasp = split_budget_gamma_column(df_ssgrasp)\n",
    "df_ssgrasp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice we have 25 executions for each instance file (and respective alpha parameter). For result comparison, we will need one worstcase cost per instance and budget_Gamma. For now, we will group by instance file in order to obtain the smallest worstcase cost found after 25 SimGRASP executions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_ssgrasp_min_worstcost = df_ssgrasp.groupby(['n', 'm', 'alpha', 'instance_name', 'stochsol_exp_cost', 'stochsol_time', \n",
    "#                                               'budget_Gamma', 'Gamma1', 'Gamma2']).min()\n",
    "ssgrasp_columns = ['n', 'm', 'alpha', 'instance_name', 'budget_Gamma', 'Gamma1', 'Gamma2']\n",
    "df_ssgrasp_min_worstcost = df_ssgrasp[df_ssgrasp['worstcase_cost'] == df_ssgrasp.groupby(ssgrasp_columns)['worstcase_cost']\n",
    "                                                                                  .transform('min')]\n",
    "df_ssgrasp_min_worstcost = df_ssgrasp_min_worstcost.sort_values(ssgrasp_columns).drop_duplicates(ssgrasp_columns)\n",
    "df_ssgrasp_max_worstcost = df_ssgrasp[df_ssgrasp['worstcase_cost'] == df_ssgrasp.groupby(ssgrasp_columns)['worstcase_cost']\n",
    "                                                                                  .transform('max')]\n",
    "df_ssgrasp_max_worstcost = df_ssgrasp_max_worstcost.sort_values(ssgrasp_columns).drop_duplicates(ssgrasp_columns)\n",
    "\n",
    "display(df_ssgrasp_min_worstcost.tail(4))\n",
    "display(df_ssgrasp_max_worstcost.tail(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ssgrasp_min_worstcost[(df_ssgrasp_min_worstcost['instance_name'] == 'RB0101001.txt')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Robust dataframe self-join "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets join the `rpfs` dataframe with itself (inner join). This will be useful to compare Wilson and Wagner models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_columns = ['n', 'm', 'alpha', 'instance_name', 'Gamma1', 'Gamma2']\n",
    "df_rob_self = pd.merge(df_rpfs, df_rpfs, how='inner', on=join_columns)\n",
    "df_rob_self = df_rob_self[(df_rob_self['model_x'] != df_rob_self['model_y'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rob_self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table 1. Average worst-case Cmax Wagner "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.pivot_table(df_rpfs_wagner, values='cmax_dp', index=['Gamma1', 'Gamma2'], columns=['alpha', 'n'], aggfunc='mean', fill_value=0)\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None): \n",
    "    display(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table 2. Average run time Wagner robust model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.pivot_table(df_rpfs_wagner, values='time', index=['Gamma1', 'Gamma2'], columns=['alpha', 'n'], aggfunc='mean', fill_value=0)\n",
    "table = np.round(table, 2)\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None): \n",
    "    display(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table 3. Performance all instances "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rob_self['x_wins_y_time'] = (df_rob_self['time_x'] < df_rob_self['time_y']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.pivot_table(df_rob_self, columns=['n', 'model_x'], values=['time_x', 'gap_x', 'iterations_x', 'x_wins_y_time'],\n",
    "                       aggfunc={'time_x' : ['mean', 'std'], 'gap_x' : 'mean', 'iterations_x' : ['mean', 'std'],\n",
    "                               'x_wins_y_time' : ['sum']})  # , margins=True, fill_value=0)\n",
    "table['perc_x_wins_y_time'] = table['x_wins_y_time'] * 100 / 1250\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None): \n",
    "    display(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped = df_rpfs_wagner.groupby(['alpha', 'n', 'm', 'budget_Gamma']).agg({'cmax_dp' : ['count']}).reset_index()\n",
    "df_grouped.columns = [ ' '.join(str(i) for i in col) for col in df_grouped.columns]\n",
    "#df_grouped.reset_index(inplace=True)\n",
    "df_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.pivot_table(df_rpfs_wagner, values='cmax_dp', index=['alpha', 'n'], columns=['Gamma1', 'Gamma2'], aggfunc='count', fill_value=0)\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None): \n",
    "    display(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a dataframe joining the `df_rpfs` and `df_dpfs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_columns = ['n', 'm', 'alpha', 'instance_name', 'Gamma1', 'Gamma2']\n",
    "df_det_d0 = df_dpfs[(df_dpfs['perc_deviation_p_bar'] == 0)]\n",
    "df_det_d100 = df_dpfs[(df_dpfs['perc_deviation_p_bar'] == 100)]\n",
    "# join robust and deterministic dfs\n",
    "df_join_rob_det = pd.merge(df_rpfs, df_det_d0, how='inner', on=join_columns, suffixes=('_rob', '_d0'))\n",
    "df_join_rob_det = pd.merge(df_join_rob_det, df_det_d100, how='inner', on=join_columns, suffixes=('_d0', '_d100'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a dataframe concatenating `df_rpfs` and `df_dpfs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_worstcase_comparison(instance_name, palette, df_dict):\n",
    "    # https://seaborn.pydata.org/tutorial/aesthetics.html\n",
    "    concat_columns = ['instance_name', 'Gamma1', 'Gamma2', 'budget_Gamma', 'worstcase_cost']\n",
    "    for key, df_i in df_dict.items():\n",
    "        df_i = df_i[concat_columns]\n",
    "        df_i['Method'] = key\n",
    "        df_dict[key] = df_i\n",
    "    df = pd.concat(df_dict.values())\n",
    "    df = df[(df['instance_name'] == instance_name)]\n",
    "    df['budget_f'] = '(' + df['Gamma1'].map(str) + ',' + df['Gamma2'].map(str) + ')'\n",
    "    # https://www.drawingfromdata.com/setting-figure-size-using-seaborn-and-matplotlib\n",
    "    #fig, ax = plt.subplots()\n",
    "    # the size of A4 paper\n",
    "    #fig.set_size_inches(11.7, 8.27)\n",
    "    marker = ['*', '+', 'o', 'x', '^', '8', 's', 'p', 'D', 'V']\n",
    "    markers = [marker[i] for i in range(len(df[\"Method\"].unique()))]\n",
    "    linestyle = ['--', '-.', ':', 'dashed', 'dashdot', 'dotted', 'solid', '-', ' ', '']\n",
    "    linestyles = [linestyle[i] for i in range(len(df[\"Method\"].unique()))]\n",
    "    a4_dims = (12, 8.27)\n",
    "    plt.figure(figsize=a4_dims)\n",
    "    with sns.axes_style(\"whitegrid\"):\n",
    "        sns.set_context(\"paper\", font_scale=1.2, rc={\"grid.linewidth\": 2})\n",
    "        g = sns.catplot(x=\"budget_f\", y=\"worstcase_cost\",  markers=markers, linestyles=linestyles,\n",
    "                     hue=\"Method\", kind=\"point\", style=\"Method\", \n",
    "                     data=df,\n",
    "                     height=5, # make the plot 5 units high\n",
    "                     aspect=3,  # height should be three times width\n",
    "                     legend=False, palette=palette)\n",
    "        plt.legend(loc='lower right')\n",
    "        # Remove the '.txt' at the end of instance_name\n",
    "        instance_name = instance_name[:instance_name.rfind('.txt')]\n",
    "        g.set_axis_labels(r'Budget ($\\Gamma_{1}, \\Gamma_{2}$) - Instance '+(instance_name), 'Worst-case cost')\n",
    "        plt.grid(which='major', axis='x')\n",
    "        plt.grid(which='minor', axis='y')\n",
    "        plt.show()\n",
    "        g.savefig(os.path.join(outputfolder_graph, 'worstcase_{}.pdf'.format(instance_name)))\n",
    "        #g.savefig(os.path.join(outputfolder_graph, 'worstcase_{}.pgf'.format(instance_name)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Worstcase cost : Small Uncertainty Range Instance - Example "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alpha = 10% and n = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO Comparar também com o RobPFSP - Minimax Regret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filename = 'RB0102005.txt'\n",
    "#filename = 'RB0501003.txt'  # Small Uncertainty range\n",
    "#filename = 'RB0201009.txt'  # Small Uncertainty range\n",
    "#filename = 'RB1001007.txt'  # Small Uncertainty range\n",
    "#filename = 'RB1501006.txt'  # Small Uncertainty range\n",
    "#filename = 'RB1502008.txt' # 'RB1502001.txt', 'RB1502006.txt', 'RB1502009.txt', 'RB1502010.txt'\n",
    "# filename = 'RB0201007.txt'\n",
    "#filename = 'RB0105010.txt'  # Large Uncertainty range\n",
    "plot_worstcase_comparison(filename, 'Set1', {'Det(0)' : df_det_d0, 'Det(100)' : df_det_d100, \n",
    "                                     'SimGRASP-Min(25)' : df_ssgrasp_min_worstcost, 'SimGRASP-Max(25)' : df_ssgrasp_max_worstcost,\n",
    "                                     r'Rob($\\Gamma_{1}, \\Gamma_{2}$)' : df_rpfs_wagner})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Worstcase cost : Large Uncertainty Range Instance - Example "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alpha = 50% and n = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'RB0105005.txt'\n",
    "#filename = 'RB0105010.txt'  # Large Uncertainty range: 'RB0505006.txt', 'RB0505003.txt', 'RB1005003.txt', 'RB1005006.txt', 'RB1005008.txt', 'RB1005009.txt'\n",
    "#filename = 'RB1505001.txt'  # 'RB0205001.txt', 'RB0205003.txt', 'RB0205008.txt', 'RB0205009.txt', 'RB0505010.txt', 'RB0505009.txt'\n",
    "# 'RB1505008.txt', 'RB1505007.txt', 'RB1505006.txt', 'RB1505004.txt', 'RB1505001.txt'\n",
    "plot_worstcase_comparison(filename, 'Set1', {'Det(0)' : df_det_d0, 'Det(100)' : df_det_d100, \n",
    "                                     'SimGRASP-Min(25)' : df_ssgrasp_min_worstcost, 'SimGRASP-Max(25)' : df_ssgrasp_max_worstcost,\n",
    "                                     r'Rob($\\Gamma_{1}, \\Gamma_{2}$)' : df_rpfs_wagner})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_instance_solution_info(df_rpfs, instance_name):\n",
    "    return df_rpfs[(df_rpfs['instance_name'] == instance_name)][['Gamma1', 'Gamma2', 'is_optimal', \n",
    "                                                                   'validated', 'gap', 'time', 'optimal']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_instance_solution_info(df_rpfs, 'RB1505002.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Monte Carlo Simulation results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulations were undertaken for 3 probability distributions: lognormal, triangular and uniform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_results_folder_det_rob = os.path.join(os.path.abspath('..'), 'pfsp_experiments', 'montecarlo_sim_2rpfs', \n",
    "                                  '2020_06_29-22_29_49-4752183a-ba47-11ea-1f13-43a2532b2fa8')\n",
    "sim_results_folder_simgrasp = sim_results_folder_det_rob\n",
    "sim_results_folder_ssgrasp = os.path.join(os.path.abspath('..'), 'pfsp_experiments', 'SimGRASP_Ying_outputs')\n",
    "print('[Det, Rob] Using simulation results folder: ', sim_results_folder_det_rob)\n",
    "print('[SimGRASP] Using simulation results folder: ', sim_results_folder_simgrasp)\n",
    "print('[SSGRASP] Using simulation results folder: ', sim_results_folder_ssgrasp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_simulation_result_csv_to_series(filename):\n",
    "    #print('Reading file: ', filename)\n",
    "    df = pd.read_csv(filename, index_col=False, header=0, names=['Makespan'])\n",
    "    series = df['Makespan'] # here we convert the DataFrame into a Series\n",
    "    return series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_budget_simulation_results_to_series(root_folder, instance_name, alpha, distribution, gamma1, gamma2, num_iter=10000):\n",
    "    folder = os.path.join(root_folder, 'robust_pfsp', distribution, 'alpha{}%'.format(alpha))\n",
    "    filename = 'MCS_rob_{}_{}_{}_{}_{}_iter{}.txt.gz'.format(gamma1, gamma2, instance_name, alpha, distribution, num_iter)\n",
    "    filepath = os.path.join(folder, filename)\n",
    "    return read_simulation_result_csv_to_series(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_deterministic_simulation_results_to_series(root_folder, instance_name, alpha, distribution, perc_variation, num_iter=10000):\n",
    "    folder = os.path.join(root_folder, 'deterministic_pfsp', distribution, 'alpha{}%'.format(alpha))\n",
    "    filename = 'MCS_det{}_{}_{}_{}_iter{}.txt.gz'.format(perc_variation, instance_name, alpha, distribution, num_iter)\n",
    "    filepath = os.path.join(folder, filename)\n",
    "    return read_simulation_result_csv_to_series(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_ssgrasp_raw_outputs_to_series(filepath):\n",
    "    with gzip.open(filepath, 'rt') as content_file:\n",
    "        content = content_file.read()\n",
    "        content = content[content.find('STOCH')+5:]\n",
    "        #content = content[content.find('DET')+3:content.find('STOCH')]\n",
    "        content = content.replace(\"\\n\", \"\")\n",
    "        s = pd.Series([float(x) for x in content.split()], name='Makespan')\n",
    "        #s.to_csv(os.path.join(os.getcwd(), \"temp.csv\"), index=False, header=0)\n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_stochastic_simulation_results_to_series(root_folder, instance_name, alpha, distribution, raw=True, num_iter=10000):\n",
    "    if raw:  # RB0105001_10_2_t_1.0_0.1_124341_outputsList.txt\n",
    "        m = 2\n",
    "        n = int(instance_name[2:5])\n",
    "        grasp_instance_name = 'RB{}50{}'.format(instance_name[2:5], instance_name[7:9])\n",
    "        filename = '{}_{}_{}_t_{:.1f}_{:.1f}_*_outputsList.txt.gz'.format(grasp_instance_name, n, m, 1.0, alpha / 100)\n",
    "        files = glob.glob(os.path.join(root_folder, filename))\n",
    "        series_list = []\n",
    "        for filepath in files:\n",
    "            series_list.append(read_ssgrasp_raw_outputs_to_series(filepath))\n",
    "        result = pd.concat(series_list)\n",
    "        return result\n",
    "    else:\n",
    "        folder = os.path.join(root_folder, 'simgrasp', distribution, 'alpha{}%'.format(alpha))\n",
    "        filename = 'MCS_SimGRASP_{}_{}_{}_iter{}.txt.gz'.format(instance_name, alpha, distribution, num_iter)\n",
    "        filepath = os.path.join(folder, filename)\n",
    "        return read_simulation_result_csv_to_series(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_violin_compare_distributions(df, instance_name, ax, seq, palette=\"Blues_d\"):\n",
    "    # https://towardsdatascience.com/violin-plots-explained-fb1d115e023d\n",
    "    #a4_dims = (11.7, 8.27)\n",
    "    #plt.figure(figsize=a4_dims)\n",
    "    with sns.axes_style(\"whitegrid\"):\n",
    "        #style.use('ggplot')\n",
    "        sns.set_context(\"paper\", rc={\"grid.linewidth\": 2, \"xtick.major.pad\": 11})  # font_scale=1.2, \n",
    "        ax = sns.violinplot(ax=ax,y=\"Makespan\", x=\"Method\",   # x=\"Makespan\", y=\"Method\", \n",
    "                               #hue=\"Method\", #kind=\"violin\", \n",
    "                               style=\"Method\", \n",
    "                     data=df, palette=palette, \n",
    "                     scale=\"area\", cut=0, inner='box', \n",
    "                     # width=0.8, showmeans=True, showextrema=True, showmedians=True\n",
    "                     height=10, # make the plot 5 units high\n",
    "                     aspect=2.5) # height should be three times width\n",
    "        ax.set_xticklabels(\n",
    "            ax.get_xticklabels(), \n",
    "            rotation=45, \n",
    "            #horizontalalignment='right',\n",
    "            fontweight='light',\n",
    "            fontsize='large'\n",
    "        )\n",
    "        # Set Background color: https://stackoverflow.com/questions/25238442/setting-plot-background-colour-in-seaborn\n",
    "        ax.set_facecolor('#f0f0f0')\n",
    "        instance_name = instance_name[:instance_name.rfind('.txt')]\n",
    "        ax.set_title('Simulation result from {} distribution'.format(distribution))\n",
    "        if seq == 0:\n",
    "            ax.set_ylabel('Makespan')\n",
    "        else:\n",
    "            ax.set_ylabel('')\n",
    "        ax.set_xlabel('Solution Method')\n",
    "        # Draw interval grid lines\n",
    "        ax.grid(which='major', axis='x')\n",
    "        ax.grid(which='minor', axis='y')\n",
    "        #plt.set_title('Instance '+instance_name)\n",
    "        #plt.show()\n",
    "        #ax.get_figure().savefig(os.path.join(outputfolder_graph, 'violin_{}.pdf'.format(instance_name)))\n",
    "        #display(sns.plotting_context())\n",
    "        #chart.savefig(os.path.join(outputfolder_graph, 'violin_{}.pgf'.format(instance_name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_kde_compare_distributions(dict_s, instance_name, ax, seq, palette):\n",
    "    #a4_dims = (11.7, 8.27)\n",
    "    #plt.figure(figsize=a4_dims)\n",
    "    #print('Number os series to plot: ' + str(len(dict_s.keys())))\n",
    "    marker = ['*', '+', 'o', 'x', '^', '8', 's', 'p', 'D', 'V', 'A', 'T']\n",
    "    markers = [marker[i] for i in range(len(dict_s.keys()))]\n",
    "    linestyle = ['--', '-.', ':', 'dashed', 'dashdot', 'dotted', 'solid', '-', ' ', '', 'None']\n",
    "    # New line styles > 12\n",
    "    # https://stackoverflow.com/questions/33337989/how-to-draw-more-type-of-lines-in-matplotlib/33338727\n",
    "    linestyles = [linestyle[i] for i in range(len(dict_s.keys()))]\n",
    "    with sns.axes_style(\"whitegrid\"):            \n",
    "        #style.use('ggplot')\n",
    "        sns.set_style(\"whitegrid\")\n",
    "        sns.set(style=\"white\", palette=palette, color_codes=True)\n",
    "        sns.set_context(\"notebook\", rc={\"grid.linewidth\": 2, \"xtick.major.pad\": 11})  # font_scale=1.2, \n",
    "        i = 0\n",
    "        for method, series in dict_s.items():\n",
    "            chart = sns.distplot(series, label=method, kde=True, hist=False, ax=ax, \n",
    "                         vertical=False, kde_kws=dict(ls=linestyle[i],dashes=linestyle_tuple[i][1][1]))  \n",
    "            # markers=markers, \n",
    "            i += 1\n",
    "        # Set Background color: https://stackoverflow.com/questions/25238442/setting-plot-background-colour-in-seaborn\n",
    "        #chart.set_facecolor('#ffffff')\n",
    "        ax.set_title('Simulation result from {} distribution'.format(distribution))\n",
    "        all_fonts_size = 12\n",
    "        if seq == 0:\n",
    "            ax.set_ylabel('Probability Distribution', fontsize=all_fonts_size)\n",
    "        ax.set_xlabel('Makespan', fontsize=all_fonts_size)\n",
    "        ax.tick_params(labelsize=all_fonts_size)\n",
    "        ax.grid(which='major', axis='x')\n",
    "        ax.grid(which='minor', axis='y')\n",
    "        #plt.show()\n",
    "        #chart.get_figure().savefig(os.path.join(outputfolder_graph, 'kde_{}.pdf'.format(instance_name)))\n",
    "        #chart.savefig(os.path.join(outputfolder_graph, 'kde_{}.pgf'.format(instance_name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_simulation_comparison(sim_results_folder_det_rob, sim_results_folder_ssgrasp, instance_name,  \n",
    "                               exclude_results=None, palette=\"Blues_d\", graph_type=\"violin\"):\n",
    "    # https://towardsdatascience.com/violin-plots-explained-fb1d115e023d\n",
    "    a4_dims = (15, 5)\n",
    "    #plt.figure(figsize=a4_dims)\n",
    "    fig, axs = plt.subplots(1, 3, sharey=True, figsize=a4_dims)\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    for d, distribution in enumerate(['lognormal', 'uniform', 'triangular']):\n",
    "        alpha = int(instance_name[5:7])\n",
    "        simulated_solutions_dict = dict()\n",
    "\n",
    "        for gamma1 in [20, 40, 60, 80, 100]:\n",
    "            for gamma2 in [20, 40, 60, 80, 100]:\n",
    "                simulated_solutions_dict['Rob({},{})'.format(gamma1, gamma2)] = read_budget_simulation_results_to_series(\n",
    "                                                                                sim_results_folder_det_rob, \n",
    "                                                                                filename, alpha, distribution, gamma1, gamma2)\n",
    "        simulated_solutions_dict['Det(100)'] = read_deterministic_simulation_results_to_series(sim_results_folder_det_rob, \n",
    "                                                                                               instance_name, \n",
    "                                                                                               alpha, distribution, 100)\n",
    "        simulated_solutions_dict['Det(0)'] = read_deterministic_simulation_results_to_series(sim_results_folder_det_rob, \n",
    "                                                                                               instance_name, \n",
    "                                                                                               alpha, distribution, 0)\n",
    "        #simulated_solutions_dict['SimGRASP(MCS_Java)'] = read_stochastic_simulation_results_to_series(sim_results_folder_ssgrasp, \n",
    "        #                                                                                    instance_name, alpha, \n",
    "        #                                                                                    distribution, True)\n",
    "        simulated_solutions_dict['SimGRASP'] = read_stochastic_simulation_results_to_series(sim_results_folder_simgrasp, \n",
    "                                                                                            instance_name, alpha, \n",
    "                                                                                            distribution, False)\n",
    "        df_list = []\n",
    "        filtered_solutions_dict = dict()\n",
    "        for key, s_i in simulated_solutions_dict.items():\n",
    "            df_i = s_i.to_frame()\n",
    "            df_i['Method'] = key\n",
    "            df_i['Distribution'] = distribution\n",
    "            if key not in exclude_results:\n",
    "                df_list.append(df_i)\n",
    "                filtered_solutions_dict[key] = s_i\n",
    "        df = pd.concat(df_list)\n",
    "        if graph_type == 'violin':\n",
    "            plot_violin_compare_distributions(df, instance_name, axs[d], d, palette)\n",
    "        else:  # kde plot\n",
    "            plot_kde_compare_distributions(filtered_solutions_dict, instance_name, axs[d], d, palette)\n",
    "        #axs[d].yaxis.tick_right()\n",
    "    plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "    instance_name = instance_name[:instance_name.rfind('.txt')]\n",
    "    if graph_type == 'violin':\n",
    "        fig.suptitle('Instance ' + instance_name, fontsize=12)\n",
    "        fig.savefig(os.path.join(outputfolder_graph, 'violinplot_{}.pdf'.format(instance_name)))\n",
    "    else:  # kde plot\n",
    "        fig.suptitle('Instance ' + instance_name, fontsize=12)\n",
    "        fig.savefig(os.path.join(outputfolder_graph, 'kdeplot_{}.pdf'.format(instance_name)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected cost : Small Uncertainty Range Instance - Example "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alpha = 10% and n = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO Traçar uma linha dentro do gráfico do violin plot, demarcando o valor do worst-case makespan (dado pelo robusto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "filename = 'RB0201009.txt'  # Small Uncertainty range\n",
    "filename = 'RB0501003.txt'  # Small Uncertainty range\n",
    "filename = 'RB1001007.txt'  # Small Uncertainty range\n",
    "filename = 'RB1501006.txt'  # Small Uncertainty range\n",
    "filename = 'RB0102005.txt'\n",
    "#filename = 'RB1502008.txt' # 'RB1502001.txt', 'RB1502006.txt', 'RB1502009.txt', 'RB1502010.txt'\n",
    "#filename = 'RB0201007.txt'\n",
    "    # 'RB1501006.txt'  # Small Uncertainty range\n",
    "    #(40,20) -> [(40, 40), (40, 60), (40,80)]; (60,40)->[(60,60), (60,80)]\n",
    "    #(80,40) -> [(80,60), (80,80)]\n",
    "    #(100,40) -> [(100,60), (100,80)]\n",
    "plot_simulation_comparison(sim_results_folder_det_rob, sim_results_folder_ssgrasp, filename, palette='summer_r', \n",
    "                           #exclude_results=[],\n",
    "                           exclude_results=['Rob(20,40)', 'Rob(20,60)', 'Rob(20,80)', 'Rob(20,100)', 'Rob(40,60)', \n",
    "                                            'Rob(40,80)', 'Rob(40,100)', 'Rob(80,80)', \n",
    "                                            'Rob(60,40)', 'Rob(60,60)', 'Rob(60,100)', 'Rob(80,60)', 'Rob(80,100)', \n",
    "                                            'Rob(100,20)', 'Rob(100,40)', 'Rob(100,60)', 'Rob(100,80)', 'Rob(100,100)'],\n",
    "                           graph_type='violin')\n",
    "                           # distribution_list=['lognormal', 'uniform']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos traçar um gráfico de KDE com a distribuição de valores de cada simulação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_simulation_comparison(sim_results_folder_det_rob, sim_results_folder_ssgrasp, filename, palette='Dark2', # Dark2, Set3\n",
    "                           exclude_results=['Rob(20,40)', 'Rob(20,60)', 'Rob(20,80)', 'Rob(20,100)', 'Rob(40,60)', \n",
    "                                            'Rob(40,80)', 'Rob(40,100)', 'Rob(80,80)', 'Rob(40,40)', 'Rob(60,80)',\n",
    "                                            'Rob(60,40)', 'Rob(60,60)', 'Rob(60,100)', 'Rob(80,60)', 'Rob(80,100)', \n",
    "                                            'Rob(100,20)', 'Rob(100,40)', 'Rob(100,60)', 'Rob(100,80)', 'Rob(100,100)',\n",
    "                                            'Det(0)', 'Det(100)'],\n",
    "                           graph_type='kde')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected cost : Large Uncertainty Range Instance - Example "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alpha = 50% and n = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filename = 'RB0105010.txt'  # Large Uncertainty range: 'RB0505006.txt', 'RB0505003.txt', 'RB1005003.txt', 'RB1005006.txt', 'RB1005008.txt', 'RB1005009.txt'\n",
    "#filename = 'RB1005001.txt'  # 'RB0205001.txt', 'RB0205003.txt', 'RB0205008.txt', 'RB0205009.txt', 'RB0505010.txt', 'RB0505009.txt'\n",
    "# 'RB1505008.txt', 'RB1505007.txt', 'RB1505006.txt', 'RB1505004.txt', 'RB1505001.txt'\n",
    "filename = 'RB0105005.txt'\n",
    "plot_simulation_comparison(sim_results_folder_det_rob, sim_results_folder_ssgrasp, filename, \n",
    "                          exclude_results=['Rob(20,20)', 'Rob(20,60)', 'Rob(20,80)', 'Rob(20,100)', 'Rob(40,60)', \n",
    "                                            'Rob(40,80)', 'Rob(40,100)', 'Rob(80,80)', 'Rob(40,40)', 'Rob(60,80)',\n",
    "                                            'Rob(60,80)', 'Rob(60,100)', 'Rob(80,60)', 'Rob(80,80)', \n",
    "                                            'Rob(100,20)', 'Rob(100,40)', 'Rob(100,60)', 'Rob(100,80)', 'Rob(100,100)',\n",
    "                                            'Det(0)', 'Det(100)', 'Rob(60,60)'],\n",
    "                          graph_type='violin')\n",
    "                           #distribution_list=['lognormal', 'uniform'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_simulation_comparison(sim_results_folder_det_rob, sim_results_folder_ssgrasp, filename, graph_type='kde',\n",
    "                          exclude_results=['Rob(20,20)', 'Rob(20,60)', 'Rob(20,80)', 'Rob(20,100)', 'Rob(40,60)', \n",
    "                                            'Rob(40,80)', 'Rob(40,100)', 'Rob(80,80)', 'Rob(40,40)', 'Rob(60,80)',\n",
    "                                            'Rob(60,80)', 'Rob(60,100)', 'Rob(80,60)', 'Rob(80,80)', \n",
    "                                            'Rob(100,20)', 'Rob(100,40)', 'Rob(100,60)', 'Rob(100,80)', 'Rob(100,100)',\n",
    "                                            'Det(0)', 'Det(100)', 'Rob(60,60)'],\n",
    "                          palette='Set3')   # Paired, hsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export the dataset to CSV file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
